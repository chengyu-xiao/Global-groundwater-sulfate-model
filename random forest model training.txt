import math
import numpy as np
import pandas 
from collections import Counter
from sklearn.datasets import make_classification
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score, cross_validate
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score, auc, roc_curve, average_precision_score,classification_report,precision_recall_curve
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, cohen_kappa_score
from sklearn.preprocessing import MinMaxScaler
from bayes_opt import BayesianOptimization
from imblearn.combine import SMOTETomek


# import training data
rd_training = pandas.read_csv('TrainingData.csv', header=0)
rd_training

y = rd_training.sulfate_binary 
x = rd_training.drop(['sulfate','sulfate_binary'], axis=1)  


# data split
x_train, x_1, y_train, y_1= train_test_split(x, y, test_size=0.2, stratify=y, random_state=42)
x_train2, x_2, y_train2, y_2 = train_test_split(x_train, y_train,  test_size=0.25, stratify=y_train, random_state=42)
x_train3, x_3, y_train3, y_3 = train_test_split(x_train2, y_train2, test_size=1/3, stratify=y_train2, random_state=42)
x_5, x_4, y_5, y_4= train_test_split(x_train3, y_train3, test_size=0.5, stratify=y_train3, random_state=42)
print(y_1.shape,y_2.shape,y_3.shape,y_4.shape,y_5.shape)

def calc_metrics(labels_test, test_probs, threshold = 0.5):
    scores = [1 if x>=threshold else 0 for x in test_probs]
    auc = roc_auc_score(labels_test, test_probs)
    kappa = cohen_kappa_score(labels_test,scores)
    confusion = confusion_matrix(labels_test,scores, labels=list(set(labels_test)))
    print('thresh: %.2f, kappa: %.3f, AUC test-set: %.3f'%(threshold, kappa, auc))
    print(confusion)
    print(classification_report(labels_test,scores))
    return 

# model training and validation 1
x_train_1 = pandas.concat([x_1, x_2, x_3, x_4], axis=0)
y_train_1 = pandas.concat([y_1, y_2, y_3, y_4], axis=0)
def bo_rf(n_estimators, max_features, min_samples_leaf):
        val = cross_val_score(
               RandomForestClassifier(n_estimators=int(n_estimators),max_features=int(max_features),
                           min_samples_leaf=int(min_samples_leaf),
                           random_state=42),x_train_1 , y_train_1 , scoring='roc_auc', cv=5).mean()
        return val
RF_bo = BayesianOptimization(bo_rf, {'n_estimators': (1000, 5000),
        'max_features': (1, 15),
        'min_samples_leaf': (1, 10)})
RF_bo.maximize(init_points=5,   
                   n_iter=10,  
                   )
print(RF_bo.max)


# model testing 1

x_train_1 = pandas.concat([x_1, x_2, x_3, x_4], axis=0)
y_train_1 = pandas.concat([y_1, y_2, y_3, y_4], axis=0)
st = SMOTETomek(random_state = 42)
x_bigtrain_re_1, y_bigtrain_re_1 = st.fit_resample(x_train_1, y_train_1)
print('Resampled dataset shape %s' % Counter(y_bigtrain_re_1))
rfc_cv_1 = RandomForestClassifier(n_estimators=1290, max_features=4, oob_score =True, min_samples_leaf = 7,random_state = 0) 
rfc_cv_1.fit(x_bigtrain_re_1, y_bigtrain_re_1)

# performance metrics
y_test_pred_5 = rfc_cv_1.predict(x_5)
y_test_probs_5 = rfc_cv_1.predict_proba(x_5)[:,1]
cm_test = confusion_matrix(y_5, y_test_pred_5, labels=[0, 1])
TN,FP,FN,TP = confusion_matrix(y_5,y_test_pred_5, labels=[0, 1]).ravel()
accuracy_test = round((TP+TN)/(TP+TN+FP+FN),2)
Sensitivity_test, Specificity_test = round(TP/(TP+FN),2),round(TN/(TN+FP),2)
cohen_kappa_score_test = round(cohen_kappa_score(y_5,y_test_pred_5),2)
print("Test cohen's kappa:",cohen_kappa_score_test)
print("Test accuracy:",accuracy_test)
print("Test Sensitivity:",Sensitivity_test, "Test Specificity:",Specificity_test)
predictions_validation = rfc_cv_1.predict_proba(x_5)[:, 1]
fpr, tpr, _ = roc_curve(y_5, predictions_validation)
roc_auc = auc(fpr, tpr)
print('ROC_AUC',round(roc_auc,2))

# Compute sensitivity and specificity at different cutoff thresholds
cutoffs = np.linspace(0, 1, 101)
sensitivities = []
specificities = []
for cutoff in cutoffs:
    y_pred_cutoff = (y_test_probs_5 > cutoff).astype(int)
    tn, fp, fn, tp = confusion_matrix(y_5, y_pred_cutoff).ravel()
    sensitivity = tp / (tp + fn)
    specificity = tn / (tn + fp)
    sensitivities.append(sensitivity)
    specificities.append(specificity)

# Find the cutoff value for the intersection point of sensitivity and specificity
sensitivity = np.array(sensitivities)
specificity = np.array(specificities)
diff = sensitivity - specificity
idx = np.argmin(np.abs(diff))
cutoff_intersection = cutoffs[idx]

# Output the sensitivity and specificity at the intersection point
print('Sensitivity at the intersection point:', round(sensitivity[idx],2))
print('Specificity at the intersection point:', round(specificity[idx],2))

# Plot the cutoff threshold and sensitivity and specificity
plt.plot(cutoffs, sensitivities, label='Sensitivity')
plt.plot(cutoffs, specificities, label='Specificity')
plt.xlabel('Cutoff threshold')
plt.ylabel('Sensitivity / Specificity')
plt.title('Sensitivity and Specificity vs Cutoff')
plt.legend()
plt.plot(cutoff_intersection, sensitivity[idx], 'ro', label='Intersection')
plt.show()
print('Cutoff value for sensitivity and specificity intersection:', round(cutoff_intersection,2))

# Compute sensitivity and specificity at different cutoff thresholds
cutoffs = np.linspace(0, 1, 101)
sensitivities = []
specificities = []
for cutoff in cutoffs:
    y_pred_cutoff = (y_test_probs_5 > cutoff).astype(int)
    tn, fp, fn, tp = confusion_matrix(y_5, y_pred_cutoff).ravel()
    sensitivity = tp / (tp + fn)
    specificity = tn / (tn + fp)
    sensitivities.append(sensitivity)
    specificities.append(specificity)

# Find the cutoff value for sensitivity = 0.9
sensitivity = np.array(sensitivities)
specificity = np.array(specificities)
target_sensitivity = 0.9
idx_2 = np.where(sensitivity <= target_sensitivity)[0][0]

# Calculate cutoff and specificity at sensitivity = 0.9
cutoff_at_sensitivity_09 = cutoffs[idx_2]
specificity_at_sensitivity_09 = specificity[idx_2]
print('Cutoff at sensitivity = 0.9:', cutoff_at_sensitivity_09)
print('Specificity at sensitivity = 0.9:', round(specificity_at_sensitivity_09,2))

# model training and validation 2
x_train_2 = pandas.concat([x_1, x_2, x_3, x_5], axis=0)
y_train_2 = pandas.concat([y_1, y_2, y_3, y_5], axis=0)
def bo_rf(n_estimators, max_features, min_samples_leaf):
        val = cross_val_score(
               RandomForestClassifier(n_estimators=int(n_estimators),max_features=int(max_features),
                           min_samples_leaf=int(min_samples_leaf),
                           random_state=42), x_train_2 , y_train_2 , scoring='roc_auc', cv=5).mean()
        return val
RF_bo = BayesianOptimization(bo_rf, {'n_estimators': (1000, 5000),
        'max_features': (1, 15),
        'min_samples_leaf': (1, 10)})
RF_bo.maximize(init_points=5,   
                   n_iter=10,  
                   )
print(RF_bo.max)

# model testing 2

x_train_2 = pandas.concat([x_1, x_2, x_3, x_5], axis=0)
y_train_2 = pandas.concat([y_1, y_2, y_3, y_5], axis=0)
st = SMOTETomek(random_state = 42)
x_bigtrain_re_2, y_bigtrain_re_2 = st.fit_resample(x_train_2, y_train_2)
print('Resampled dataset shape %s' % Counter(y_bigtrain_re_2))
rfc_cv_2 = RandomForestClassifier(n_estimators=1343, max_features=3, oob_score =True, min_samples_leaf = 3,random_state = 0) 
rfc_cv_2.fit(x_bigtrain_re_2, y_bigtrain_re_2)

# performance metrics
y_test_pred_4 = rfc_cv_2.predict(x_4)
y_test_probs_4 = rfc_cv_2.predict_proba(x_4)[:,1]
cm_test = confusion_matrix(y_4, y_test_pred_4, labels=[0, 1])
TN,FP,FN,TP = confusion_matrix(y_4,y_test_pred_4, labels=[0, 1]).ravel()
accuracy_test = round((TP+TN)/(TP+TN+FP+FN),2)
Sensitivity_test, Specificity_test = round(TP/(TP+FN),2),round(TN/(TN+FP),2)
cohen_kappa_score_test = round(cohen_kappa_score(y_4,y_test_pred_4),2)
print("Test cohen's kappa:",cohen_kappa_score_test)
print("Test accuracy:",accuracy_test)
print("Test Sensitivity:",Sensitivity_test, "Test Specificity:",Specificity_test)
predictions_validation = rfc_cv_2.predict_proba(x_4)[:, 1]
fpr, tpr, _ = roc_curve(y_4, predictions_validation)
roc_auc = auc(fpr, tpr)
print('ROC_AUC',round(roc_auc,2))

# Compute sensitivity and specificity at different cutoff thresholds
cutoffs = np.linspace(0, 1, 101)
sensitivities = []
specificities = []
for cutoff in cutoffs:
    y_pred_cutoff = (y_test_probs_4 > cutoff).astype(int)
    tn, fp, fn, tp = confusion_matrix(y_4, y_pred_cutoff).ravel()
    sensitivity = tp / (tp + fn)
    specificity = tn / (tn + fp)
    sensitivities.append(sensitivity)
    specificities.append(specificity)

# Find the cutoff value for the intersection point of sensitivity and specificity
sensitivity = np.array(sensitivities)
specificity = np.array(specificities)
diff = sensitivity - specificity
idx = np.argmin(np.abs(diff))
cutoff_intersection = cutoffs[idx]

# Output the sensitivity and specificity at the intersection point
print('Sensitivity at the intersection point:', round(sensitivity[idx],2))
print('Specificity at the intersection point:', round(specificity[idx],2))

# Plot the cutoff threshold and sensitivity and specificity
plt.plot(cutoffs, sensitivities, label='Sensitivity')
plt.plot(cutoffs, specificities, label='Specificity')
plt.xlabel('Cutoff threshold')
plt.ylabel('Sensitivity / Specificity')
plt.title('Sensitivity and Specificity vs Cutoff')
plt.legend()
plt.plot(cutoff_intersection, sensitivity[idx], 'ro', label='Intersection')
plt.show()
print('Cutoff value for sensitivity and specificity intersection:', round(cutoff_intersection,2))

# Compute sensitivity and specificity at different cutoff thresholds
cutoffs = np.linspace(0, 1, 101)
sensitivities = []
specificities = []
for cutoff in cutoffs:
    y_pred_cutoff = (y_test_probs_4 > cutoff).astype(int)
    tn, fp, fn, tp = confusion_matrix(y_4, y_pred_cutoff).ravel()
    sensitivity = tp / (tp + fn)
    specificity = tn / (tn + fp)
    sensitivities.append(sensitivity)
    specificities.append(specificity)

# Find the cutoff value for sensitivity = 0.9
sensitivity = np.array(sensitivities)
specificity = np.array(specificities)
target_sensitivity = 0.9
idx_2 = np.where(sensitivity <= target_sensitivity)[0][0]

# Calculate cutoff and specificity at sensitivity = 0.9
cutoff_at_sensitivity_09 = cutoffs[idx_2]
specificity_at_sensitivity_09 = specificity[idx_2]
print('Cutoff at sensitivity = 0.9:', cutoff_at_sensitivity_09)
print('Specificity at sensitivity = 0.9:', round(specificity_at_sensitivity_09,2))

# model training and validation 3
x_train_3 = pandas.concat([x_1, x_2, x_4, x_5], axis=0)
y_train_3 = pandas.concat([y_1, y_2, y_4, y_5], axis=0)
def bo_rf(n_estimators, max_features, min_samples_leaf):
        val = cross_val_score(
               RandomForestClassifier(n_estimators=int(n_estimators),max_features=int(max_features),
                           min_samples_leaf=int(min_samples_leaf),
                           random_state=42), x_train_3 , y_train_3 , scoring='roc_auc', cv=5).mean()
        return val
RF_bo = BayesianOptimization(bo_rf, {'n_estimators': (1000, 5000),
        'max_features': (1, 15),
        'min_samples_leaf': (1, 10)})
RF_bo.maximize(init_points=5,   
                   n_iter=10,  
                   )
print(RF_bo.max)

# model testing 3

x_train_3 = pandas.concat([x_1, x_2, x_4, x_5], axis=0)
y_train_3 = pandas.concat([y_1, y_2, y_4, y_5], axis=0)
st = SMOTETomek(random_state = 42)
x_bigtrain_re_3, y_bigtrain_re_3 = st.fit_resample(x_train_3, y_train_3)
print('Resampled dataset shape %s' % Counter(y_bigtrain_re_3))
rfc_cv_3 = RandomForestClassifier(n_estimators=2179, max_features=3, oob_score =True, min_samples_leaf = 5,random_state = 0) 
rfc_cv_3.fit(x_bigtrain_re_3, y_bigtrain_re_3)

# performance metrics
y_test_pred_3 = rfc_cv_3.predict(x_3)
y_test_probs_3 = rfc_cv_3.predict_proba(x_3)[:,1]
cm_test = confusion_matrix(y_3, y_test_pred_3, labels=[0, 1])
TN,FP,FN,TP = confusion_matrix(y_3, y_test_pred_3, labels=[0, 1]).ravel()
accuracy_test = round((TP+TN)/(TP+TN+FP+FN),2)
Sensitivity_test, Specificity_test = round(TP/(TP+FN),2),round(TN/(TN+FP),2)
cohen_kappa_score_test = round(cohen_kappa_score(y_3, y_test_pred_3),2)
print("Test cohen's kappa:",cohen_kappa_score_test)
print("Test accuracy:",accuracy_test)
print("Test Sensitivity:",Sensitivity_test, "Test Specificity:",Specificity_test)
predictions_validation = rfc_cv_3.predict_proba(x_3)[:, 1]
fpr, tpr, _ = roc_curve(y_3, predictions_validation)
roc_auc = auc(fpr, tpr)
print('ROC_AUC',round(roc_auc,2))

# Compute sensitivity and specificity at different cutoff thresholds
cutoffs = np.linspace(0, 1, 101)
sensitivities = []
specificities = []
for cutoff in cutoffs:
    y_pred_cutoff = (y_test_probs_3 > cutoff).astype(int)
    tn, fp, fn, tp = confusion_matrix(y_3, y_pred_cutoff).ravel()
    sensitivity = tp / (tp + fn)
    specificity = tn / (tn + fp)
    sensitivities.append(sensitivity)
    specificities.append(specificity)

# Find the cutoff value for the intersection point of sensitivity and specificity
sensitivity = np.array(sensitivities)
specificity = np.array(specificities)
diff = sensitivity - specificity
idx = np.argmin(np.abs(diff))
cutoff_intersection = cutoffs[idx]

# Output the sensitivity and specificity at the intersection point
print('Sensitivity at the intersection point:', round(sensitivity[idx],2))
print('Specificity at the intersection point:', round(specificity[idx],2))

# Plot the cutoff threshold and sensitivity and specificity
plt.plot(cutoffs, sensitivities, label='Sensitivity')
plt.plot(cutoffs, specificities, label='Specificity')
plt.xlabel('Cutoff threshold')
plt.ylabel('Sensitivity / Specificity')
plt.title('Sensitivity and Specificity vs Cutoff')
plt.legend()
plt.plot(cutoff_intersection, sensitivity[idx], 'ro', label='Intersection')
plt.show()
print('Cutoff value for sensitivity and specificity intersection:', round(cutoff_intersection,2))

# Compute sensitivity and specificity at different cutoff thresholds
cutoffs = np.linspace(0, 1, 101)
sensitivities = []
specificities = []
for cutoff in cutoffs:
    y_pred_cutoff = (y_test_probs_3 > cutoff).astype(int)
    tn, fp, fn, tp = confusion_matrix(y_3, y_pred_cutoff).ravel()
    sensitivity = tp / (tp + fn)
    specificity = tn / (tn + fp)
    sensitivities.append(sensitivity)
    specificities.append(specificity)

# Find the cutoff value for sensitivity = 0.9
sensitivity = np.array(sensitivities)
specificity = np.array(specificities)
target_sensitivity = 0.9
idx_2 = np.where(sensitivity <= target_sensitivity)[0][0]

# Calculate cutoff and specificity at sensitivity = 0.9
cutoff_at_sensitivity_09 = cutoffs[idx_2]
specificity_at_sensitivity_09 = specificity[idx_2]
print('Cutoff at sensitivity = 0.9:', cutoff_at_sensitivity_09)
print('Specificity at sensitivity = 0.9:', round(specificity_at_sensitivity_09,2))


# model training and validation 4
x_train_4 = pandas.concat([x_1, x_3, x_4, x_5], axis=0)
y_train_4 = pandas.concat([y_1, y_3, y_4, y_5], axis=0)
def bo_rf(n_estimators, max_features, min_samples_leaf):
        val = cross_val_score(
               RandomForestClassifier(n_estimators=int(n_estimators),max_features=int(max_features),
                           min_samples_leaf=int(min_samples_leaf),
                           random_state=42), x_train_4 , y_train_4 , scoring='roc_auc', cv=5).mean()
        return val
RF_bo = BayesianOptimization(bo_rf, {'n_estimators': (1000, 5000),
        'max_features': (1, 15),
        'min_samples_leaf': (1, 10)})
RF_bo.maximize(init_points=5,   
                   n_iter=10,  
                   )
print(RF_bo.max)


# model testing 4

x_train_4 = pandas.concat([x_1, x_3, x_4, x_5], axis=0)
y_train_4 = pandas.concat([y_1, y_3, y_4, y_5], axis=0)
st = SMOTETomek(random_state = 42)
x_bigtrain_re_4, y_bigtrain_re_4 = st.fit_resample(x_train_4, y_train_4)
print('Resampled dataset shape %s' % Counter(y_bigtrain_re_4))
rfc_cv_4 = RandomForestClassifier(n_estimators=3750, max_features=4, oob_score =True, min_samples_leaf = 6,random_state = 0) 
rfc_cv_4.fit(x_bigtrain_re_4, y_bigtrain_re_4)

# performance metrics
y_test_pred_2 = rfc_cv_4.predict(x_2)
y_test_probs_2 = rfc_cv_4.predict_proba(x_2)[:,1]
cm_test = confusion_matrix(y_2, y_test_pred_2, labels=[0, 1])
TN,FP,FN,TP = confusion_matrix(y_2,y_test_pred_2, labels=[0, 1]).ravel()
accuracy_test = round((TP+TN)/(TP+TN+FP+FN),2)
Sensitivity_test, Specificity_test = round(TP/(TP+FN),2),round(TN/(TN+FP),2)
cohen_kappa_score_test = round(cohen_kappa_score(y_2,y_test_pred_2),2)
print("Test cohen's kappa:",cohen_kappa_score_test)
print("Test accuracy:",accuracy_test)
print("Test Sensitivity:",Sensitivity_test, "Test Specificity:",Specificity_test)
predictions_validation = rfc_cv_4.predict_proba(x_2)[:, 1]
fpr, tpr, _ = roc_curve(y_2, predictions_validation)
roc_auc = auc(fpr, tpr)
print('ROC_AUC',round(roc_auc,2))

# Compute sensitivity and specificity at different cutoff thresholds
cutoffs = np.linspace(0, 1, 101)
sensitivities = []
specificities = []
for cutoff in cutoffs:
    y_pred_cutoff = (y_test_probs_2 > cutoff).astype(int)
    tn, fp, fn, tp = confusion_matrix(y_2, y_pred_cutoff).ravel()
    sensitivity = tp / (tp + fn)
    specificity = tn / (tn + fp)
    sensitivities.append(sensitivity)
    specificities.append(specificity)

# Find the cutoff value for the intersection point of sensitivity and specificity
sensitivity = np.array(sensitivities)
specificity = np.array(specificities)
diff = sensitivity - specificity
idx = np.argmin(np.abs(diff))
cutoff_intersection = cutoffs[idx]

# Output the sensitivity and specificity at the intersection point
print('Sensitivity at the intersection point:', round(sensitivity[idx],2))
print('Specificity at the intersection point:', round(specificity[idx],2))

# Plot the cutoff threshold and sensitivity and specificity
plt.plot(cutoffs, sensitivities, label='Sensitivity')
plt.plot(cutoffs, specificities, label='Specificity')
plt.xlabel('Cutoff threshold')
plt.ylabel('Sensitivity / Specificity')
plt.title('Sensitivity and Specificity vs Cutoff')
plt.legend()
plt.plot(cutoff_intersection, sensitivity[idx], 'ro', label='Intersection')
plt.show()
print('Cutoff value for sensitivity and specificity intersection:', round(cutoff_intersection,2))

# Compute sensitivity and specificity at different cutoff thresholds
cutoffs = np.linspace(0, 1, 101)
sensitivities = []
specificities = []
for cutoff in cutoffs:
    y_pred_cutoff = (y_test_probs_2 > cutoff).astype(int)
    tn, fp, fn, tp = confusion_matrix(y_2, y_pred_cutoff).ravel()
    sensitivity = tp / (tp + fn)
    specificity = tn / (tn + fp)
    sensitivities.append(sensitivity)
    specificities.append(specificity)

# Find the cutoff value for sensitivity = 0.9
sensitivity = np.array(sensitivities)
specificity = np.array(specificities)
target_sensitivity = 0.9
idx_2 = np.where(sensitivity <= target_sensitivity)[0][0]

# Calculate cutoff and specificity at sensitivity = 0.9
cutoff_at_sensitivity_09 = cutoffs[idx_2]
specificity_at_sensitivity_09 = specificity[idx_2]
print('Cutoff at sensitivity = 0.9:', cutoff_at_sensitivity_09)
print('Specificity at sensitivity = 0.9:', round(specificity_at_sensitivity_09,2))


# model training and validation 5
x_train_5 = pandas.concat([x_2, x_3, x_4, x_5], axis=0)
y_train_5 = pandas.concat([y_2, y_3, y_4, y_5], axis=0)
def bo_rf(n_estimators, max_features, min_samples_leaf):
        val = cross_val_score(
               RandomForestClassifier(n_estimators=int(n_estimators),max_features=int(max_features),
                           min_samples_leaf=int(min_samples_leaf),
                           random_state=42), x_train_5 , y_train_5 , scoring='roc_auc', cv=5).mean()
        return val
RF_bo = BayesianOptimization(bo_rf, {'n_estimators': (1000, 5000),
        'max_features': (1, 15),
        'min_samples_leaf': (1, 10)})
RF_bo.maximize(init_points=5,   
                   n_iter=10,  
                   )
print(RF_bo.max)


# model testing 5

x_train_5 = pandas.concat([x_2, x_3, x_4, x_5], axis=0)
y_train_5 = pandas.concat([y_2, y_3, y_4, y_5], axis=0)
st = SMOTETomek(random_state = 42)
x_bigtrain_re_5, y_bigtrain_re_5 = st.fit_resample(x_train_5, y_train_5)
print('Resampled dataset shape %s' % Counter(y_bigtrain_re_5))
rfc_cv_5 = RandomForestClassifier(n_estimators=1167, max_features=3, oob_score =True, min_samples_leaf = 6,random_state = 0) 
rfc_cv_5.fit(x_bigtrain_re_5, y_bigtrain_re_5)

# performance metrics
y_test_pred_1 = rfc_cv_5.predict(x_1)
y_test_probs_1 = rfc_cv_5.predict_proba(x_1)[:,1]
cm_test = confusion_matrix(y_1, y_test_pred_1, labels=[0, 1])
TN,FP,FN,TP = confusion_matrix(y_1,y_test_pred_1, labels=[0, 1]).ravel()
accuracy_test = round((TP+TN)/(TP+TN+FP+FN),2)
Sensitivity_test, Specificity_test = round(TP/(TP+FN),2),round(TN/(TN+FP),2)
cohen_kappa_score_test = round(cohen_kappa_score(y_1,y_test_pred_1),2)
print("Test cohen's kappa:",cohen_kappa_score_test)
print("Test accuracy:",accuracy_test)
print("Test Sensitivity:",Sensitivity_test, "Test Specificity:",Specificity_test)
predictions_validation = rfc_cv_5.predict_proba(x_1)[:, 1]
fpr, tpr, _ = roc_curve(y_1, predictions_validation)
roc_auc = auc(fpr, tpr)
print('ROC_AUC',round(roc_auc,2))

# Compute sensitivity and specificity at different cutoff thresholds
cutoffs = np.linspace(0, 1, 101)
sensitivities = []
specificities = []
for cutoff in cutoffs:
    y_pred_cutoff = (y_test_probs_1 > cutoff).astype(int)
    tn, fp, fn, tp = confusion_matrix(y_1, y_pred_cutoff).ravel()
    sensitivity = tp / (tp + fn)
    specificity = tn / (tn + fp)
    sensitivities.append(sensitivity)
    specificities.append(specificity)

# Find the cutoff value for the intersection point of sensitivity and specificity
sensitivity = np.array(sensitivities)
specificity = np.array(specificities)
diff = sensitivity - specificity
idx = np.argmin(np.abs(diff))
cutoff_intersection = cutoffs[idx]

# Output the sensitivity and specificity at the intersection point
print('Sensitivity at the intersection point:', round(sensitivity[idx],2))
print('Specificity at the intersection point:', round(specificity[idx],2))

# Plot the cutoff threshold and sensitivity and specificity
plt.plot(cutoffs, sensitivities, label='Sensitivity')
plt.plot(cutoffs, specificities, label='Specificity')
plt.xlabel('Cutoff threshold')
plt.ylabel('Sensitivity / Specificity')
plt.title('Sensitivity and Specificity vs Cutoff')
plt.legend()
plt.plot(cutoff_intersection, sensitivity[idx], 'ro', label='Intersection')
plt.show()
print('Cutoff value for sensitivity and specificity intersection:', round(cutoff_intersection,2))

# Compute sensitivity and specificity at different cutoff thresholds
cutoffs = np.linspace(0, 1, 101)
sensitivities = []
specificities = []
for cutoff in cutoffs:
    y_pred_cutoff = (y_test_probs_1 > cutoff).astype(int)
    tn, fp, fn, tp = confusion_matrix(y_1, y_pred_cutoff).ravel()
    sensitivity = tp / (tp + fn)
    specificity = tn / (tn + fp)
    sensitivities.append(sensitivity)
    specificities.append(specificity)

# Find the cutoff value for sensitivity = 0.9
sensitivity = np.array(sensitivities)
specificity = np.array(specificities)
target_sensitivity = 0.9
idx_2 = np.where(sensitivity <= target_sensitivity)[0][0]

# Calculate cutoff and specificity at sensitivity = 0.9
cutoff_at_sensitivity_09 = cutoffs[idx_2]
specificity_at_sensitivity_09 = specificity[idx_2]
print('Cutoff at sensitivity = 0.9:', cutoff_at_sensitivity_09)
print('Specificity at sensitivity = 0.9:', round(specificity_at_sensitivity_09,2))


# final random forest model training using entire dataset

st = SMOTETomek(random_state = 42)
x_re, y_re = st.fit_resample(x, y)
rfc_final = RandomForestClassifier(n_estimators=1946, max_features=3, min_samples_leaf = 5,random_state = 0) 
rfc_final.fit(x_re, y_re)
